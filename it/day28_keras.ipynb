{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import os\n",
    "import tarfile\n",
    "\n",
    "url=\"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n",
    "filepath=\"IMDb/aclImdb_v1.tar.gz\"\n",
    "if not os.path.isfile(filepath):\n",
    "    result=urllib.request.urlretrieve(url,filepath)\n",
    "    print('downloaded:',result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "#將html的標籤刪除\n",
    "import re\n",
    "def rm_htmltags(text):\n",
    "    re_tag = re.compile(r'<[^>]+>')\n",
    "    return re_tag.sub('', text)\n",
    "\n",
    "#讀取IMDb的檔案目錄\n",
    "import os\n",
    "def read_files(filetype):\n",
    "    path = \"IMDb/aclImdb/\"\n",
    "    file_list=[]\n",
    "\n",
    "    positive_path=path + filetype+\"/pos/\"\n",
    "    for f in os.listdir(positive_path):\n",
    "        file_list+=[positive_path+f]\n",
    "    \n",
    "    negative_path=path + filetype+\"/neg/\"\n",
    "    for f in os.listdir(negative_path):\n",
    "        file_list+=[negative_path+f]\n",
    "        \n",
    "    print('read',filetype, 'files:',len(file_list))\n",
    "       \n",
    "    all_labels = ([1] * 12500 + [0] * 12500) \n",
    "    \n",
    "    all_texts  = []\n",
    "    for fi in file_list:\n",
    "        with open(fi,encoding='utf8') as file_input:\n",
    "            all_texts += [rm_htmltags(\" \".join(file_input.readlines()))]\n",
    "            \n",
    "    return all_labels,all_texts\n",
    "    \n",
    "#查看IMDb的檔案目錄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read train files: 25000\n",
      "read test files: 25000\n"
     ]
    }
   ],
   "source": [
    "y_train, train_text = read_files(\"train\")\n",
    "y_test, test_text = read_files(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#先讀取所有文章建立dic，限制dic數量為nb_words=2500\n",
    "token = Tokenizer(num_words=2500)\n",
    "token.fit_on_texts(train_text)\n",
    "#查看文字index的屬性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bromwell High is a cartoon comedy. It ran at the same time as some other programs about school life, such as \"Teachers\". My 35 years in the teaching profession lead me to believe that Bromwell High's satire is much closer to reality than is \"Teachers\". The scramble to survive financially, the insightful students who can see right through their pathetic teachers' pomp, the pettiness of the whole situation, all remind me of the schools I knew and their students. When I saw the episode in which a student repeatedly tried to burn down the school, I immediately recalled ......... at .......... High. A classic line: INSPECTOR: I'm here to sack one of your teachers. STUDENT: Welcome to Bromwell High. I expect that many adults of my age think that Bromwell High is far fetched. What a pity that it isn't!\n",
      "[308, 6, 3, 1068, 208, 8, 2160, 29, 1, 168, 54, 13, 45, 81, 40, 391, 109, 137, 13, 57, 149, 7, 1, 481, 68, 5, 260, 11, 2000, 6, 72, 2422, 5, 631, 70, 6, 1, 5, 2001, 1, 1530, 33, 66, 63, 204, 139, 64, 1229, 1, 4, 1, 222, 899, 28, 68, 4, 1, 9, 693, 2, 64, 1530, 50, 9, 215, 1, 386, 7, 59, 3, 1470, 798, 5, 176, 1, 391, 9, 1235, 29, 308, 3, 352, 343, 142, 129, 5, 27, 4, 125, 1470, 2372, 5, 308, 9, 532, 11, 107, 1466, 4, 57, 554, 100, 11, 308, 6, 226, 47, 3, 2231, 11, 8, 214]\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import sequence \n",
    "\n",
    "x_train_seq = token.texts_to_sequences(train_text)\n",
    "x_test_seq  = token.texts_to_sequences(test_text)\n",
    "\n",
    "print(train_text[0])\n",
    "print(x_train_seq[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set model\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation,Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(output_dim=32,\n",
    "                    input_dim=2000, \n",
    "                    input_length=100))\n",
    "model.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 100, 32)           64000     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 100, 32)           0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               819456    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 883,713\n",
      "Trainable params: 883,713\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.add(Flatten())\n",
    "model.add(Dense(units=256,\n",
    "                activation='relu' ))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=1,\n",
    "                activation='sigmoid' ))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 利用反向演算法訓練模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = sequence.pad_sequences(x_train_seq, maxlen=100)\r\n",
    "x_test = sequence.pad_sequences(x_test_seq, maxlen=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-e4e4637eddb8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#verbose：顯示每次的訓練過程\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#validation_split：測試資料的比例\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m train_history =model.fit(x_train, y_train,batch_size=100,\n\u001b[0m\u001b[0;32m      8\u001b[0m                          epochs=10,verbose=2,validation_split=0.25)\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x_train' is not defined"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy',metrics=['accuracy'])\n",
    "#進行訓練\n",
    "#batch_size：每一批次訓練100筆資料\n",
    "#epochs：執行10個訓練週期\n",
    "#verbose：顯示每次的訓練過程\n",
    "#validation_split：測試資料的比例\n",
    "train_history =model.fit(x_train, y_train,batch_size=100,\n",
    "                         epochs=10,verbose=2,validation_split=0.25)\n",
    "                      \n",
    "#評估訓練模型的準確率\n",
    "acu = model.evaluate(x_test, y_test, verbose=1)\n",
    "acu[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立RNN模型\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import SimpleRNN\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(output_dim=32,\n",
    "                    input_dim=3800, \n",
    "                    input_length=380))\n",
    "model.add(Dropout(0.25))\n",
    "#建立18個RNN神經元\n",
    "model.add(SimpleRNN(units=18))\n",
    "model.add(Dense(units=256,activation='relu' ))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(units=1,activation='sigmoid' ))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 預測模型的準確率\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "scores[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "practice",
   "language": "python",
   "name": "practice"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}